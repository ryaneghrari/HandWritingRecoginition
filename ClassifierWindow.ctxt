#BlueJ class context
comment0.params=
comment0.target=ClassifierWindow()
comment1.params=whichButton
comment1.target=void\ buttonClicked(javax.swing.JButton)
comment10.params=x
comment10.target=Jama.Matrix\ logisticFunction(Jama.Matrix)
comment10.text=\ \n\ This\ method\ takes\ as\ input\ column\ vector,\ and\ creates\ a\ matrix\ whose\ entries\ are\n\ the\ values\ of\ the\ logistic\ function\ performed\ on\ the\ entries\ of\ the\ input\ matrix.\n
comment11.params=input\ theta1\ theta2
comment11.target=Jama.Matrix\ computeHypothesis(Jama.Matrix,\ Jama.Matrix,\ Jama.Matrix)
comment11.text=\ \n\ This\ method\ takes\ as\ input\ a\ single\ input\ vector\ (without\ bias\ unit\ --\ you'll\ need\ to\ add\ that),\ along\ with\ the\ weight\ matrices,\ and\n\ computes\ the\ output\ vector\ of\ the\ neural\ network.\ That\ is,\ it\ performs\ forward\ propagation.\n
comment12.params=inputs\ biasVal
comment12.target=Jama.Matrix\ addBiasUnit(Jama.Matrix,\ double)
comment13.params=input
comment13.target=Jama.Matrix\ removeFirstElement(Jama.Matrix)
comment14.params=hypothesis
comment14.target=boolean\ validHypothesis(Jama.Matrix)
comment14.text=\ This\ is\ a\ helper\ method.\ \ It\ takes\ as\ input\ a\ matrix\ that\ results\ from\ the\ output\ of\ the\ neural\ network,\ and\ checks\n\ that\ this\ vector\ is\ valid\ (all\ entries\ are\ between\ 0\ and\ 1).\ \ You\ may\ not\ need\ it.\ \ I\ did.\n
comment15.params=trainingData\ outputData\ thetaValues\ lambdaValue
comment15.target=Jama.Matrix[]\ gradientCheck(Jama.Matrix[],\ Jama.Matrix[],\ Jama.Matrix[],\ double)
comment15.text=\ This\ method\ takes\ as\ input\ an\ array\ of\ matrices\ that\ represent\ the\ input\ training\ data,\ an\ array\ of\ matrices\ that\ represent\n\ the\ corresponding\ output\ data,\ an\ array\ of\ matrices\ that\ represent\ the\ weight\ matrices\ (well,\ the\ [1]\ and\ [2]\ index\ \n\ members\ do),\ and\ the\ value\ of\ lambda.\ \ It\ returns\ an\ array\ of\ matrices,\ each\ of\ which\ represents\ some\ (but\ not\ all)\ of\n\ the\ partial\ derivatives\ (with\ respect\ to\ the\ individual\ theta\ entries)\ of\ the\ theta\ matrices.\ \ In\ particular,\ the\n\ [1]\ index\ matrix\ of\ the\ output\ should\ correspond\ to\ the\ partials\ of\ theta[1].\ \ The\ [2]\ index\ matrix\ of\ the\ output\ should\n\ corresponds\ to\ the\ partials\ of\ theta[2].\ \ When\ computing\ the\ partials,\ you\ should\ use\ GRADIENT_CHECKING_EPSILON\n\ as\ the\ value\ of\ epsilon\ for\ gradient\ approximation\ purposes.\n
comment16.params=trainingData\ outputData\ thetaValues\ lambdaValue
comment16.target=double\ jTheta(Jama.Matrix[],\ Jama.Matrix[],\ Jama.Matrix[],\ double)
comment16.text=\ \n\ This\ method\ takes\ as\ input\ an\ array\ of\ matrices\ that\ represent\ the\ input\ training\ data,\ an\ array\ of\ matrices\ that\ represent\n\ the\ corresponding\ output\ data,\ an\ array\ of\ matrices\ that\ represent\ the\ weight\ matrices\ (well,\ the\ [1]\ and\ [2]\ index\ \n\ members\ do),\ and\ the\ value\ of\ lambda.\ \ It\ returns\ a\ double\ value\ that\ represents\ the\ value\ of\ the\ cost\ function\ J(theta)\ for\n\ this\ choice\ of\ training\ data,\ theta\ values,\ and\ lambda.\n
comment17.params=m
comment17.target=double\ sumSquaredMatrixEntries(Jama.Matrix)
comment17.text=\ You\ don't\ have\ to\ code\ this,\ but\ you\ might\ find\ it\ helpful\ for\ computing\ jTheta.\ \ \n\ It\ takes\ as\ input\ a\ matrix.\ \ It\ computes\ the\ sum\ of\ the\ squares\ of\ each\ matrix\ entry,\n\ with\ the\ exception\ of\ the\ first\ column\ of\ the\ matrix,\ which\ it\ ignores.\n
comment18.params=name\ m
comment18.target=void\ printMatrixDimensions(java.lang.String,\ Jama.Matrix)
comment18.text=\ A\ helper\ method.\ \ When\ debugging,\ it's\ sometimes\ convenient\ to\ be\ able\ to\ easily\ print\ out\ the\ dimensions\ of\ \n\ a\ matrix,\ along\ with\ a\ string\ that\ identifies\ to\ you\ which\ matrix\ this\ method\ is\ measuring.\n
comment19.params=event
comment19.target=void\ mousePressed(java.awt.event.MouseEvent)
comment2.params=
comment2.target=void\ trainMatrix()
comment20.params=event
comment20.target=void\ mouseReleased(java.awt.event.MouseEvent)
comment21.params=e
comment21.target=void\ mouseEntered(java.awt.event.MouseEvent)
comment22.params=event
comment22.target=void\ mouseExited(java.awt.event.MouseEvent)
comment23.params=whichLabel
comment23.target=void\ labelClicked(javax.swing.JLabel)
comment24.params=
comment24.target=void\ clearImage()
comment25.params=color
comment25.target=char\ getColorChar(java.awt.Color)
comment26.params=
comment26.target=void\ saveImage()
comment27.params=whichComboBox
comment27.target=void\ selectionMade(javax.swing.JComboBox)
comment3.params=m
comment3.target=int\ getMax(Jama.Matrix)
comment3.text=\ This\ method\ assumes\ that\ the\ input\ is\ a\ column\ vector\ (that\ is,\ a\ matrix\ with\ only\ a\ single\n\ row.\ \ It\ goes\ through\ the\ values\ in\ the\ matrix,\ and\ returns\ the\ ROW\ INDEX\ of\ the\ largest\ entry\ in\ the\n\ matrix\n
comment4.params=
comment4.target=Jama.Matrix[]\ performBackPropagation()
comment4.text=\ \n\ This\ method\ assumes\ that\ the\ readTrainingData()\ method\ has\ been\ previously\ run,\ so\n\ that\ the\ training\ and\ output\ arrays\ have\ already\ been\ filled.\ \ If\ this\ assumption\ is\ not\n\ valid,\ this\ method\ will\ likely\ throw\ a\ NullPointerException.\ \ IMPORTANT\:\ AN\ ASSUMPTION\ OF\ THIS\n\ METHOD\ SHOULD\ BE\ THAT\ THE\ TRAINING\ VECTORS\ IN\ THE\ input\ ARRAY\ DO\ NOT\ HAVE\ BIAS\ UNITS.\ \ You\ will\n\ have\ to\ write\ code\ that\ adds\ that\ bias\ unit\ before\ you\ can\ perform\ back\ propagation\ with\ the\n\ vectors.\n
comment5.params=
comment5.target=void\ readTrainingData()
comment6.params=yValue
comment6.target=Jama.Matrix\ vectorizeY(java.lang.String)
comment6.text=\ This\ method\ should\ take\ as\ input\ a\ String\ representing\ a\ single\ digit\ (the\ correct\ digit)\ and\ creates\ the\n\ correct\ output\ matrix\ for\ that\ digit.\ \ So,\ for\ example,\ if\ the\ input\ String\ is\ "4",\ the\ output\ matrix\ should\n\ be\ the\ 10\ x\ 1\ matrix\n\ \n\ \ \ \ \ 0\n\ \ \ \ \ 0\n\ \ \ \ \ 0\n\ \ \ \ \ 0\n\ \ \ \ \ 1\n\ \ \ \ \ 0\n\ \ \ \ \ 0\n\ \ \ \ \ 0\n\ \ \ \ \ 0\n\ \ \ \ \ 0\n\ \ \n
comment7.params=input
comment7.target=Jama.Matrix\ inputStringToMatrix(java.lang.String)
comment7.text=\ This\ method\ takes\ as\ input\ a\ String\ representing\ the\ binary\ representation\ of\ a\ digit.\ \ Since\ the\ String\ should\n\ have\ length\ INPUT_VECTOR_DIMENSION,\ one\ should\ end\ up\ with\ a\ matrix\ that\ has\ dimensions\n\ INPUT_VECTROR_DIMENSION\ x\ 1.\ \ Note\ that\ the\ \n\ \n
comment8.params=rows\ cols
comment8.target=Jama.Matrix\ createInitialTheta(int,\ int)
comment8.text=\ This\ method\ takes\ as\ input\ the\ size\ (number\ of\ rows\ and\ number\ of\ cols)\ of\ a\ matrix,\ and\ creates\ a\ matrix\n\ of\ the\ given\ size,\ which\ has\ random\ entries.\ \ All\ entries\ of\ the\ matrix\ should\ fall\ between\ -epsilon\ and\ +epsilon,\n\ where\ epsilon\ is\ the\ instance\ variable\ of\ the\ same\ name.\n
comment9.params=x
comment9.target=double\ logisticFunction(double)
comment9.text=\ \n\ This\ method\ takes\ a\ double\ as\ input,\ and\ output\ the\ value\ of\ the\ logistic\ function\ when\ applied\ to\ x.\n
numComments=28
